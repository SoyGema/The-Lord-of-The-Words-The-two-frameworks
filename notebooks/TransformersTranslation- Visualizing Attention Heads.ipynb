{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa9690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LogIn and \n",
    "## Download a model from the Hub T5 --> mirarlo \n",
    "## Upload the model from the Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1296ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer , DataCollatorForSeq2Seq , AdamWeightDecay , TFAutoModelForSeq2SeqLM\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import numpy as np\n",
    "from transformers import AdamWeightDecay\n",
    "from transformers import TFAutoModelForSeq2SeqLM\n",
    "import tensorflow as tf\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "from transformers.keras_callbacks import PushToHubCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b315cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc722ca7e1041218480e78e1b9e70c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44591417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_huggin(argument):\n",
    "  \"Load the subset from datasets library\"\n",
    "  books = load_dataset(\"opus_books\", argument)\n",
    "  return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea5f3f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset opus_books (/Users/gema/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac25e204f3f24b9fa9e693c686f591bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "english_italian = load_dataset_huggin(\"en-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7230c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(argument):\n",
    "  \"Load the subset from datasets library\"\n",
    "  books = argument[\"train\"].train_test_split(test_size=0.2)\n",
    "  return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05acba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = split_train_test(english_italian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e7f809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '11812',\n",
       " 'translation': {'en': 'Its eyes blue. Its nose is a delicate red, with spots.',\n",
       "  'it': 'È un cane bianco dagli occhi azzurri, dal naso d’un rosso delicato con chiazze nere.'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[\"train\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "787be6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint , use_fast=False)\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9394f237",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"tft5_for_conditional_generation\" (type TFT5ForConditionalGeneration).\n\nData of type <class 'torch.Tensor'> is not allowed only (<class 'tensorflow.python.framework.ops.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>, <class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'>) is accepted for decoder_input_ids.\n\nCall arguments received by layer \"tft5_for_conditional_generation\" (type TFT5ForConditionalGeneration):\n  • input_ids=tensor([[  451,   217,     7,     8,   422, 17926,     5,     1]])\n  • attention_mask=None\n  • decoder_input_ids=tensor([[  292, 10262,   177,     3,  7647,  8021, 12351,   324,     5,     1]])\n  • decoder_attention_mask=None\n  • head_mask=None\n  • decoder_head_mask=None\n  • encoder_outputs=None\n  • past_key_values=None\n  • inputs_embeds=None\n  • decoder_inputs_embeds=None\n  • labels=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mas_target_tokenizer():\n\u001b[1;32m      3\u001b[0m     decoder_input_ids \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSie sieht den kleinen Elefanten.\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[0;32m----> 5\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m encoder_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_ids_to_tokens(encoder_input_ids[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      8\u001b[0m decoder_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_ids_to_tokens(decoder_input_ids[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:433\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m--> 433\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minput_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args_and_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munpacked_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:510\u001b[0m, in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m         output[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 510\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mallowed_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is accepted for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(main_input, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(main_input):\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# EagerTensors don't allow to use the .name property so we check for a real Tensor\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"tft5_for_conditional_generation\" (type TFT5ForConditionalGeneration).\n\nData of type <class 'torch.Tensor'> is not allowed only (<class 'tensorflow.python.framework.ops.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>, <class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'>) is accepted for decoder_input_ids.\n\nCall arguments received by layer \"tft5_for_conditional_generation\" (type TFT5ForConditionalGeneration):\n  • input_ids=tensor([[  451,   217,     7,     8,   422, 17926,     5,     1]])\n  • attention_mask=None\n  • decoder_input_ids=tensor([[  292, 10262,   177,     3,  7647,  8021, 12351,   324,     5,     1]])\n  • decoder_attention_mask=None\n  • head_mask=None\n  • decoder_head_mask=None\n  • encoder_outputs=None\n  • past_key_values=None\n  • inputs_embeds=None\n  • decoder_inputs_embeds=None\n  • labels=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "###Trying to follow this https://github.com/jessevig/bertviz\n",
    "\n",
    "\n",
    "encoder_input_ids = tokenizer(\"She sees the small elephant.\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    decoder_input_ids = tokenizer(\"Sie sieht den kleinen Elefanten.\", return_tensors=\"pt\", add_special_tokens=True).input_ids\n",
    "\n",
    "outputs = model(input_ids=encoder_input_ids, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "encoder_text = tokenizer.convert_ids_to_tokens(encoder_input_ids[0])\n",
    "decoder_text = tokenizer.convert_ids_to_tokens(decoder_input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb254d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e3c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
